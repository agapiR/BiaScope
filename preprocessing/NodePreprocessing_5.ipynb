{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utilities\n",
    "from utilities import group_unfairness_score, group_unfairness_scores, recommended_nodes\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified group fairness score precomputation to include larger values of k\n",
    "# id, pos_x, pos_y, inFoRM, proj_x, proj_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # networkx positions \n",
    "# def get_node_pos(G, node_features):\n",
    "#     G = nx.read_edgelist(edgelist_file)\n",
    "#     nodes = list(G.nodes())\n",
    "\n",
    "#     start = time.time()\n",
    "#     nodePos = nx.spring_layout(G, seed=42)\n",
    "#     end = time.time()\n",
    "\n",
    "#     for node in nodes:\n",
    "#         if node not in node_features:\n",
    "#             node_features[node] = {\"id\": node}\n",
    "#         node_features[node][\"pos_x\"] = nodePos[node][0]\n",
    "#         node_features[node][\"pos_y\"] = nodePos[node][1]\n",
    "#     print(\"Spring Layout Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pca_proj(G, embeddings, node_features):\n",
    "#     start = time.time()\n",
    "#     embeddings_pca = PCA(n_components=2).fit_transform(embeddings)\n",
    "#     end = time.time()\n",
    "#     nodes = list(G.nodes())\n",
    "#     for i in range(len(nodes)):\n",
    "#         node_features[nodes[i]][\"proj_x\"] = embeddings_pca[i][0]\n",
    "#         node_features[nodes[i]][\"proj_y\"] = embeddings_pca[i][1]\n",
    "\n",
    "#     print(\"PCA Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inFoRM(G, embeddings, node_features):\n",
    "#     adj_matrix = nx.to_numpy_array(G)\n",
    "#     assert(adj_matrix.max() == 1)\n",
    "#     start = time.time()\n",
    "#     inFoRM_scores = utilities.unfairness_scores_normalized(embeddings, adj_matrix, G)\n",
    "#     end = time.time()\n",
    "#     nodes = list(G.nodes())\n",
    "#     for i in range(len(inFoRM_scores)):\n",
    "#         node_features[nodes[i]][\"InFoRM\"] = inFoRM_scores[i]\n",
    "#     print(\"InFoRM Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_metadata = {\"Facebook\": {\"edgelist\": \"../edgelists/facebook_combined.edgelist\"},\n",
    "#                  \"LastFM\": {\"edgelist\": \"../edgelists/lastfm_asia_edges.edgelist\"},\n",
    "#                  \"wikipedia\": {\"edgelist\": \"../edgelists/wikipedia.edgelist\"},\n",
    "#                   \"protein-protein\": {\"edgelist\": \"../edgelists/ppi.edgelist\"},\n",
    "#                   \"ca-HepTh\": {\"edgelist\": \"../edgelists/ca-HepTh.edgelist\"},\n",
    "#                   \"AutonomousSystems\": {\"edgelist\": \"../edgelists/AS.edgelist\"},\n",
    "#                  }\n",
    "graph_metadata = {\"Facebook\": {\"edgelist\": \"../edgelists/facebook_combined.edgelist\", \n",
    "                                \"features\":\"../edgelists/facebook/node_genders.txt\"},\n",
    "                    # \"Ex1\": {\"edgelist\": \"../edgelists/facebook_combined.edgelist\", \n",
    "                    #             \"features\":\"../edgelists/facebook/node_genders.txt\"}          \n",
    "                 }\n",
    "embedding_algs = [\"Node2Vec\", \"HOPE\", \"HGCN\", \"LaplacianEigenmap\", \"SDNE\", \"SVD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate csv file with ... and InFoRM fairness score\n",
    "# for graph_name in graph_metadata:\n",
    "#     print(\"\\n\\n\" + graph_name)\n",
    "#     node_features = {}\n",
    "\n",
    "#     edgelist_file = graph_metadata[graph_name][\"edgelist\"]\n",
    "#     G = nx.read_edgelist(edgelist_file)\n",
    "#     get_node_pos(G, node_features)\n",
    "    \n",
    "#     for embedding_alg in embedding_algs:\n",
    "#         print(\"\\n\" + embedding_alg)\n",
    "#         embedding_file = \"../embeddings/{}/{}/{}_{}_64_embedding.npy\".format(graph_name, \n",
    "#                                                                              embedding_alg, \n",
    "#                                                                              graph_name, \n",
    "#                                                                              embedding_alg)\n",
    "#         embeddings = np.load(embedding_file)\n",
    "        \n",
    "#         node_features_copy = node_features.copy()\n",
    "#         get_inFoRM(G, embeddings, node_features_copy)\n",
    "#         get_pca_proj(G, embeddings, node_features_copy)\n",
    "        \n",
    "#         output_file = \"../embeddings/{}/{}/{}_{}_64_embedding_node_features.csv\".format(graph_name, \n",
    "#                                                                                          embedding_alg, \n",
    "#                                                                                          graph_name, \n",
    "#                                                                                          embedding_alg)\n",
    "#         with open(output_file, \"w\") as outputCSV:\n",
    "#             outputCSV.write(\"id, pos_x, pos_y, proj_x, proj_y, InFoRM\\n\")\n",
    "#             for node_id in node_features:\n",
    "#                 outputCSV.write(\"{}, {}, {}, {}, {}, {}\\n\".format(node_features[node_id][\"id\"],\n",
    "#                                                                   node_features[node_id][\"pos_x\"],\n",
    "#                                                                   node_features[node_id][\"pos_y\"],\n",
    "#                                                                   node_features[node_id][\"proj_x\"],\n",
    "#                                                                   node_features[node_id][\"proj_y\"],\n",
    "#                                                                   node_features[node_id][\"InFoRM\"]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927921483689403\n",
      "0.7430751155719137\n",
      "0.8323047160858801\n"
     ]
    }
   ],
   "source": [
    "edgelist_file = graph_metadata[\"Facebook\"][\"edgelist\"]\n",
    "G = nx.read_edgelist(edgelist_file)\n",
    "W = nx.to_numpy_array(G)\n",
    "\n",
    "def dict_node_id2idx(G):\n",
    "    dict_node_id2idx = {}\n",
    "    for i,v in enumerate(G.nodes()):\n",
    "        dict_node_id2idx[v] = i\n",
    "    return dict_node_id2idx\n",
    "def dict_node_idx2id(G):\n",
    "    dict_node_idx2id = {}\n",
    "    for i,v in enumerate(G.nodes()):\n",
    "        dict_node_idx2id[i] = v\n",
    "    return dict_node_idx2id\n",
    "\n",
    "def check_symmetric(a, tol=1e-8):\n",
    "    return np.all(np.abs(a-a.T) < tol)\n",
    "\n",
    "# print(check_symmetric(W))\n",
    "# print(W)\n",
    "# print(not W[0,0])\n",
    "# print(not W[0,1])\n",
    "\n",
    "idx1 = dict_node_id2idx(G)['1234']\n",
    "idx2 = dict_node_id2idx(G)['1111']\n",
    "#print(W[idx1][idx2])\n",
    "\n",
    "#print(G.nodes())\n",
    "# for i,v in enumerate(G.nodes()):\n",
    "#     if v=='1512':\n",
    "#         print(i)\n",
    "\n",
    "# for v in ['364', '501', '441', '564', '399', '393', '476', '351', '464', '578']:\n",
    "#     print(dict_node_id2idx(G)[v])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embedding_file = \"../embeddings/{}/{}/{}_{}_64_embedding.npy\".format(\"Facebook\", \n",
    "                                                                    \"HGCN\", \n",
    "                                                                    \"Facebook\", \n",
    "                                                                    \"HGCN\")\n",
    "Y = np.load(embedding_file)\n",
    "\n",
    "focal = '3984'\n",
    "focal_idx = dict_node_id2idx(G)[focal]\n",
    "neighbors = ['3980']\n",
    "#['0', '89', '95', '147', '219', '319']\n",
    "neighbors_idx = [dict_node_id2idx(G)[n] for n in neighbors]\n",
    "\n",
    "score = 0\n",
    "for n_idx in neighbors_idx:\n",
    "    score += np.linalg.norm(Y[focal_idx]-Y[n_idx])**2\n",
    "\n",
    "#print(score)\n",
    "\n",
    "max_score = score/G.degree[focal]\n",
    "\n",
    "print(max_score)\n",
    "\n",
    "\n",
    "\n",
    "focal = '3812'\n",
    "focal_idx = dict_node_id2idx(G)[focal]\n",
    "neighbors = ['3459', '3437', '3536', '3549', '3682', '3662', '3745']\n",
    "neighbors_idx = [dict_node_id2idx(G)[n] for n in neighbors]\n",
    "\n",
    "score = 0\n",
    "for n_idx in neighbors_idx:\n",
    "    score += np.linalg.norm(Y[focal_idx]-Y[n_idx])**2\n",
    "\n",
    "norm_score = (score/G.degree[focal])/max_score\n",
    "\n",
    "print(score/G.degree[focal])\n",
    "\n",
    "print(norm_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Facebook\n",
      "\n",
      "Node2Vec\n",
      "\n",
      "HOPE\n",
      "\n",
      "HGCN\n",
      "\n",
      "LaplacianEigenmap\n",
      "\n",
      "SDNE\n",
      "\n",
      "SVD\n"
     ]
    }
   ],
   "source": [
    "# generate csv file with group fairness parameters and score\n",
    "# nodeid, sensitive attribute (S), value (z), k, g.f. score\n",
    "for graph_name in graph_metadata:\n",
    "    print(\"\\n\\n\" + graph_name)\n",
    "    # node_features = {}\n",
    "\n",
    "    edgelist_file = graph_metadata[graph_name][\"edgelist\"]\n",
    "    G = nx.read_edgelist(edgelist_file)\n",
    "    W = nx.to_numpy_array(G)\n",
    "    \n",
    "    for embedding_alg in embedding_algs:\n",
    "        print(\"\\n\" + embedding_alg)\n",
    "        embedding_file = \"../embeddings/{}/{}/{}_{}_64_embedding.npy\".format(graph_name, \n",
    "                                                                             embedding_alg, \n",
    "                                                                             graph_name, \n",
    "                                                                             embedding_alg)\n",
    "        embedding = np.load(embedding_file)        \n",
    "\n",
    "        # select output file\n",
    "        output_file_gf = \"../embeddings/{}/{}/{}_{}_64_embedding_recommended_nodes.csv\".format(graph_name, \n",
    "                                                                                         embedding_alg, \n",
    "                                                                                         graph_name, \n",
    "                                                                                         embedding_alg)\n",
    "\n",
    "\n",
    "        # create a dict nodeId->sensitive_attrs_val\n",
    "        # recommended_nodes(Y,W,node_idx,k)\n",
    "        # dict node_id -> row in W\n",
    "        dict_node_id2idx = {}\n",
    "        dict_node_idx2id = {}\n",
    "        for i,v in enumerate(G.nodes()):\n",
    "            dict_node_id2idx[v] = i\n",
    "            dict_node_idx2id[i] = v\n",
    "\n",
    "        with open(output_file_gf, \"w\") as outputCSV:\n",
    "            outputCSV.write(\"id,k,recommended_nodes\\n\")\n",
    "\n",
    "            for node_id in G.nodes():\n",
    "                node_idx = dict_node_id2idx[node_id]\n",
    "\n",
    "                for k in [25]: # define possible values for k\n",
    "                    # compute recommended nodes\n",
    "                    rho_u_idx = recommended_nodes(embedding,W,node_idx,k)\n",
    "                    # write data to csv file\n",
    "                    rho_u_id = []\n",
    "                    for recnode_idx in rho_u_idx:\n",
    "                        rho_u_id.append(dict_node_idx2id[recnode_idx])\n",
    "\n",
    "                    outputCSV.write(\"{},{},{}\\n\".format(node_id,\n",
    "                                            k,\n",
    "                                            rho_u_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
