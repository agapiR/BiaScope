{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id, pos_x, pos_y, inFoRM, proj_x, proj_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networkx positions \n",
    "def get_node_pos(G, node_features):\n",
    "    G = nx.read_edgelist(edgelist_file)\n",
    "    nodes = list(G.nodes())\n",
    "\n",
    "    start = time.time()\n",
    "    nodePos = nx.spring_layout(G, seed=42)\n",
    "    end = time.time()\n",
    "\n",
    "    for node in nodes:\n",
    "        if node not in node_features:\n",
    "            node_features[node] = {\"id\": node}\n",
    "        node_features[node][\"pos_x\"] = nodePos[node][0]\n",
    "        node_features[node][\"pos_y\"] = nodePos[node][1]\n",
    "    print(\"Spring Layout Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_proj(G, embeddings, node_features):\n",
    "    start = time.time()\n",
    "    embeddings_pca = PCA(n_components=2).fit_transform(embeddings)\n",
    "    end = time.time()\n",
    "    nodes = list(G.nodes())\n",
    "    for i in range(len(nodes)):\n",
    "        node_features[nodes[i]][\"proj_x\"] = embeddings_pca[i][0]\n",
    "        node_features[nodes[i]][\"proj_y\"] = embeddings_pca[i][1]\n",
    "\n",
    "    print(\"PCA Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inFoRM(G, embeddings, node_features):\n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    assert(adj_matrix.max() == 1)\n",
    "    start = time.time()\n",
    "    inFoRM_scores = utilities.unfairness_scores_normalized(embeddings, adj_matrix, G)\n",
    "    end = time.time()\n",
    "    nodes = list(G.nodes())\n",
    "    for i in range(len(inFoRM_scores)):\n",
    "        node_features[nodes[i]][\"InFoRM\"] = inFoRM_scores[i]\n",
    "    print(\"InFoRM Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inFoRM_hops(G, embeddings, node_features, nr_hops):\n",
    "#     # adj_matrix = nx.to_numpy_array(G)\n",
    "#     # assert(adj_matrix.max() == 1)\n",
    "#     start = time.time()\n",
    "#     inFoRM_hops_scores = utilities.uk_hop_InFoRM_scores_normalized(embeddings, G, nr_hops)\n",
    "#     end = time.time()\n",
    "#     nodes = list(G.nodes())\n",
    "#     for i in range(len(inFoRM_hops_scores)):\n",
    "#         node_features[nodes[i]][\"InFoRM_hops\"] = inFoRM_hops_scores[i]\n",
    "#     print(\"InFoRM hops Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Facebook\n",
      "Spring Layout Elapsed Time: 40\n",
      "\n",
      "Node2Vec\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HOPE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HGCN\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "LaplacianEigenmap\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SDNE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SVD\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "\n",
      "LastFM\n",
      "Spring Layout Elapsed Time: 153\n",
      "\n",
      "Node2Vec\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HOPE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HGCN\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "LaplacianEigenmap\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SDNE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SVD\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "\n",
      "wikipedia\n",
      "Spring Layout Elapsed Time: 69\n",
      "\n",
      "Node2Vec\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HOPE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HGCN\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "LaplacianEigenmap\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SDNE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SVD\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "\n",
      "protein-protein\n",
      "Spring Layout Elapsed Time: 38\n",
      "\n",
      "Node2Vec\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HOPE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "HGCN\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "LaplacianEigenmap\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SDNE\n",
      "PCA Elapsed Time: 0\n",
      "\n",
      "SVD\n",
      "PCA Elapsed Time: 0\n"
     ]
    }
   ],
   "source": [
    "graph_metadata = {\"Facebook\": {\"edgelist\": \"../edgelists/facebook_combined.edgelist\"},\n",
    "                 \"LastFM\": {\"edgelist\": \"../edgelists/lastfm_asia_edges.edgelist\"},\n",
    "                 \"wikipedia\": {\"edgelist\": \"../edgelists/wikipedia.edgelist\"},\n",
    "                  \"protein-protein\": {\"edgelist\": \"../edgelists/ppi.edgelist\"},\n",
    "                #   \"ca-HepTh\": {\"edgelist\": \"../edgelists/ca-HepTh.edgelist\"},\n",
    "                #   \"AutonomousSystems\": {\"edgelist\": \"../edgelists/AS.edgelist\"},\n",
    "                 }\n",
    "embedding_algs = [\"Node2Vec\", \"HOPE\", \"HGCN\", \"LaplacianEigenmap\", \"SDNE\", \"SVD\"]\n",
    "\n",
    "for graph_name in graph_metadata:\n",
    "    print(\"\\n\\n\" + graph_name)\n",
    "    node_features = {}\n",
    "\n",
    "    edgelist_file = graph_metadata[graph_name][\"edgelist\"]\n",
    "    G = nx.read_edgelist(edgelist_file)\n",
    "\n",
    "    get_node_pos(G, node_features)\n",
    "\n",
    "    # dict node_id <-> row in W (node idx)\n",
    "    dict_node_id2idx = {}\n",
    "    dict_node_idx2id = {}\n",
    "    for i,v in enumerate(G.nodes()):\n",
    "        dict_node_id2idx[v] = i\n",
    "        dict_node_idx2id[i] = v\n",
    "    \n",
    "    for embedding_alg in embedding_algs:\n",
    "        print(\"\\n\" + embedding_alg)\n",
    "        embedding_file = \"../embeddings/{}/{}/{}_{}_64_embedding.npy\".format(graph_name, \n",
    "                                                                             embedding_alg, \n",
    "                                                                             graph_name, \n",
    "                                                                             embedding_alg)\n",
    "        embeddings = np.load(embedding_file)\n",
    "        \n",
    "        node_features_copy = node_features.copy()\n",
    "        get_pca_proj(G, embeddings, node_features_copy)\n",
    "        \n",
    "        output_file = \"../embeddings/{}/{}/{}_{}_64_embedding_node_features_InFoRM_scores.csv\".format(graph_name, \n",
    "                                                                                         embedding_alg, \n",
    "                                                                                         graph_name, \n",
    "                                                                                         embedding_alg)\n",
    "        adj_matrix = nx.to_numpy_array(G) # only needed for consistency check\n",
    "        # inFoRM_1_score = utilities.unfairness_scores_normalized(embeddings, adj_matrix, G) # only needed for consistency check\n",
    "        with open(output_file, \"w\") as outputCSV:\n",
    "            outputCSV.write(\"id,pos_x,pos_y,proj_x,proj_y,nr_hops,InFoRM_hops\\n\")\n",
    "            for nr_hops in range(1,3):\n",
    "                inFoRM_hops_score = utilities.k_hop_InFoRM_scores_normalized(embeddings, G, nr_hops)\n",
    "                \n",
    "                for node_id in node_features:\n",
    "                    node_idx = dict_node_id2idx[node_id]\n",
    "                    \n",
    "                    outputCSV.write(\"{},{},{},{},{},{},{}\\n\".format(node_features[node_id][\"id\"],\n",
    "                                                                    node_features[node_id][\"pos_x\"],\n",
    "                                                                    node_features[node_id][\"pos_y\"],\n",
    "                                                                    node_features[node_id][\"proj_x\"],\n",
    "                                                                    node_features[node_id][\"proj_y\"],\n",
    "                                                                    nr_hops,\n",
    "                                                                    inFoRM_hops_score[node_idx])) # needs idx\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
