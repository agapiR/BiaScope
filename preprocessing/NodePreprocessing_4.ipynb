{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utilities\n",
    "from utilities import group_unfairness_score, group_unfairness_scores\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified group fairness score precomputation to include larger values of k\n",
    "# id, pos_x, pos_y, inFoRM, proj_x, proj_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networkx positions \n",
    "def get_node_pos(G, node_features):\n",
    "    G = nx.read_edgelist(edgelist_file)\n",
    "    nodes = list(G.nodes())\n",
    "\n",
    "    start = time.time()\n",
    "    nodePos = nx.spring_layout(G, seed=42)\n",
    "    end = time.time()\n",
    "\n",
    "    for node in nodes:\n",
    "        if node not in node_features:\n",
    "            node_features[node] = {\"id\": node}\n",
    "        node_features[node][\"pos_x\"] = nodePos[node][0]\n",
    "        node_features[node][\"pos_y\"] = nodePos[node][1]\n",
    "    print(\"Spring Layout Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_proj(G, embeddings, node_features):\n",
    "    start = time.time()\n",
    "    embeddings_pca = PCA(n_components=2).fit_transform(embeddings)\n",
    "    end = time.time()\n",
    "    nodes = list(G.nodes())\n",
    "    for i in range(len(nodes)):\n",
    "        node_features[nodes[i]][\"proj_x\"] = embeddings_pca[i][0]\n",
    "        node_features[nodes[i]][\"proj_y\"] = embeddings_pca[i][1]\n",
    "\n",
    "    print(\"PCA Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inFoRM(G, embeddings, node_features):\n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    assert(adj_matrix.max() == 1)\n",
    "    start = time.time()\n",
    "    inFoRM_scores = utilities.unfairness_scores_normalized(embeddings, adj_matrix, G)\n",
    "    end = time.time()\n",
    "    nodes = list(G.nodes())\n",
    "    for i in range(len(inFoRM_scores)):\n",
    "        node_features[nodes[i]][\"InFoRM\"] = inFoRM_scores[i]\n",
    "    print(\"InFoRM Elapsed Time: {}\".format(int(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_metadata = {\"Facebook\": {\"edgelist\": \"../edgelists/facebook_combined.edgelist\"},\n",
    "#                  \"LastFM\": {\"edgelist\": \"../edgelists/lastfm_asia_edges.edgelist\"},\n",
    "#                  \"wikipedia\": {\"edgelist\": \"../edgelists/wikipedia.edgelist\"},\n",
    "#                   \"protein-protein\": {\"edgelist\": \"../edgelists/ppi.edgelist\"},\n",
    "#                   \"ca-HepTh\": {\"edgelist\": \"../edgelists/ca-HepTh.edgelist\"},\n",
    "#                   \"AutonomousSystems\": {\"edgelist\": \"../edgelists/AS.edgelist\"},\n",
    "#                  }\n",
    "graph_metadata = {\"Facebook\": {\"edgelist\": \"../edgelists/facebook_combined.edgelist\", \n",
    "                                \"features\":\"../edgelists/facebook/node_genders.txt\"},\n",
    "                    # \"Ex1\": {\"edgelist\": \"../edgelists/facebook_combined.edgelist\", \n",
    "                    #             \"features\":\"../edgelists/facebook/node_genders.txt\"}          \n",
    "                 }\n",
    "embedding_algs = [\"Node2Vec\", \"HOPE\", \"HGCN\", \"LaplacianEigenmap\", \"SDNE\", \"SVD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate csv file with ... and InFoRM fairness score\n",
    "# for graph_name in graph_metadata:\n",
    "#     print(\"\\n\\n\" + graph_name)\n",
    "#     node_features = {}\n",
    "\n",
    "#     edgelist_file = graph_metadata[graph_name][\"edgelist\"]\n",
    "#     G = nx.read_edgelist(edgelist_file)\n",
    "#     get_node_pos(G, node_features)\n",
    "    \n",
    "#     for embedding_alg in embedding_algs:\n",
    "#         print(\"\\n\" + embedding_alg)\n",
    "#         embedding_file = \"../embeddings/{}/{}/{}_{}_64_embedding.npy\".format(graph_name, \n",
    "#                                                                              embedding_alg, \n",
    "#                                                                              graph_name, \n",
    "#                                                                              embedding_alg)\n",
    "#         embeddings = np.load(embedding_file)\n",
    "        \n",
    "#         node_features_copy = node_features.copy()\n",
    "#         get_inFoRM(G, embeddings, node_features_copy)\n",
    "#         get_pca_proj(G, embeddings, node_features_copy)\n",
    "        \n",
    "#         output_file = \"../embeddings/{}/{}/{}_{}_64_embedding_node_features.csv\".format(graph_name, \n",
    "#                                                                                          embedding_alg, \n",
    "#                                                                                          graph_name, \n",
    "#                                                                                          embedding_alg)\n",
    "#         with open(output_file, \"w\") as outputCSV:\n",
    "#             outputCSV.write(\"id, pos_x, pos_y, proj_x, proj_y, InFoRM\\n\")\n",
    "#             for node_id in node_features:\n",
    "#                 outputCSV.write(\"{}, {}, {}, {}, {}, {}\\n\".format(node_features[node_id][\"id\"],\n",
    "#                                                                   node_features[node_id][\"pos_x\"],\n",
    "#                                                                   node_features[node_id][\"pos_y\"],\n",
    "#                                                                   node_features[node_id][\"proj_x\"],\n",
    "#                                                                   node_features[node_id][\"proj_y\"],\n",
    "#                                                                   node_features[node_id][\"InFoRM\"]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Facebook\n",
      "\n",
      "Node2Vec\n",
      "\n",
      "HOPE\n",
      "\n",
      "HGCN\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_q/pzhhxkj13gz7sj97r2t7qqgw0000gn/T/ipykernel_58030/2982597030.py\", line 52, in <cell line: 3>\n",
      "    score = group_unfairness_score(embedding, W, node_id, node_features, attr_pos, value, k)\n",
      "  File \"/Users/brunoscarone/Documents/PhD - Northeastern/Academics/Courses/Spring 22/CS7250 - InfViz/Final Project/Github_repos/BiaScope/preprocessing/../utilities.py\", line 100, in group_unfairness_score\n",
      "  File \"/Users/brunoscarone/Documents/PhD - Northeastern/Academics/Courses/Spring 22/CS7250 - InfViz/Final Project/Github_repos/BiaScope/preprocessing/../utilities.py\", line 82, in recommended_nodes\n",
      "    # group unfairness score\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/brunoscarone/opt/anaconda3/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# generate csv file with group fairness parameters and score\n",
    "# nodeid, sensitive attribute (S), value (z), k, g.f. score\n",
    "for graph_name in graph_metadata:\n",
    "    print(\"\\n\\n\" + graph_name)\n",
    "    # node_features = {}\n",
    "\n",
    "    edgelist_file = graph_metadata[graph_name][\"edgelist\"]\n",
    "    G = nx.read_edgelist(edgelist_file)\n",
    "    W = nx.to_numpy_array(G)\n",
    "    # get_node_pos(G, node_features)\n",
    "    \n",
    "    for embedding_alg in embedding_algs:\n",
    "        print(\"\\n\" + embedding_alg)\n",
    "        embedding_file = \"../embeddings/{}/{}/{}_{}_64_embedding.npy\".format(graph_name, \n",
    "                                                                             embedding_alg, \n",
    "                                                                             graph_name, \n",
    "                                                                             embedding_alg)\n",
    "        embedding = np.load(embedding_file)\n",
    "        node_features_file = graph_metadata[graph_name][\"features\"]\n",
    "        \n",
    "        # get sensitive attributes\n",
    "        with open(node_features_file, newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                sensitive_attrs = row[1:]\n",
    "                # print('sensitive_attrs',sensitive_attrs)\n",
    "                break\n",
    "\n",
    "        node_features = np.loadtxt(open(node_features_file, \"rb\"), delimiter=\",\", skiprows=1).astype(int)\n",
    "\n",
    "        # select output file\n",
    "        output_file_gf = \"../embeddings/{}/{}/{}_{}_64_embedding_group_fairness_scores.csv\".format(graph_name, \n",
    "                                                                                         embedding_alg, \n",
    "                                                                                         graph_name, \n",
    "                                                                                         embedding_alg)\n",
    "\n",
    "        # create a dict nodeId->sensitive_attrs_val\n",
    "        # dict node_id -> row in W (node idx)\n",
    "        dict_node_id2idx = {}\n",
    "        dict_node_idx2id = {}\n",
    "        for i,v in enumerate(G.nodes()):\n",
    "            dict_node_id2idx[v] = i\n",
    "            dict_node_idx2id[i] = v\n",
    "\n",
    "        with open(output_file_gf, \"w\") as outputCSV:\n",
    "            outputCSV.write(\"id,attribute,value,k,group_fairness_score\\n\")\n",
    "\n",
    "            for node_id in G.nodes(): # node ids start from 0\n",
    "                node_idx = dict_node_id2idx[node_id]\n",
    "                for attribute in sensitive_attrs:\n",
    "                    dict_node_attr_val = dict([(node_features[i,0],node_features[i,1]) for i in range(len(node_features))])\n",
    "                    # get values from the selected attribute\n",
    "                    attr_pos = sensitive_attrs.index(attribute) + 1\n",
    "                    sensitive_attrs_vals = np.unique(node_features[:,attr_pos])\n",
    "                    for value in sensitive_attrs_vals:\n",
    "                        for k in range(5,30,5): # define possible values for k\n",
    "                            # compute group fairness score\n",
    "                            if node_id in dict_node_attr_val.keys():\n",
    "                                score = group_unfairness_score(embedding, W, node_idx, node_features, attr_pos, value, k)\n",
    "                            else:\n",
    "                                score = \"\"\n",
    "                            \n",
    "                                \n",
    "                            # score = group_unfairness_score(embedding, W, node_id, node_features, attr_pos, value, k)\n",
    "                            # write data to csv file\n",
    "                            outputCSV.write(\"{},{},{},{},{}\\n\".format(node_id,\n",
    "                                                    attribute,\n",
    "                                                    value,\n",
    "                                                    k,\n",
    "                                                    score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
